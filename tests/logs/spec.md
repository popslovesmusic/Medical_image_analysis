# Module Specification

**Path:** tests/logs
**Generated by:** Codex cleanup task
**Date:** 2025-10-31

Specification: Test Logging & Deterministic Replay System

Module Path: tests/logs/
Parent Specs:

tests/spec.md (Unified Testing Framework)

tests/fixtures/spec.md (fixture integrity)

core/meta/chronicle/spec.md (system-wide provenance chain)

trainer/spec.md (training diagnostics integration)

I. Mission

The Test Logging Subsystem provides transparent, timestamped, and cryptographically verifiable logs for every test execution.

It ensures:

Full traceability of every test input, seed, and result.

Deterministic replay‚Äîthe ability to reproduce any previous test run bit-for-bit.

Centralized auditing‚Äîa unified log format for machine and human review.

Logs are the chronological truth source of the testing layer.

II. Directory Layout
tests/logs/
‚îú‚îÄ runs/               # Raw execution logs (one per test batch)
‚îú‚îÄ summaries/          # Aggregated JSON/Markdown summaries
‚îú‚îÄ timing/             # Performance metrics and benchmarks
‚îú‚îÄ determinism/        # Replay state and seed trace logs
‚îú‚îÄ errors/             # Exception traces, failed assertions
‚îú‚îÄ coverage/           # Coverage reports from pytest-cov
‚îî‚îÄ audit/              # Immutable signed logs for releases

III. Log Categories
Category	Description	Format
Execution Logs	Per-test event trace (inputs, outputs, seed, duration)	.json, .log
Timing Logs	Per-test execution timing and resource use	.csv, .json
Error Logs	Stack traces, failed assertions, or mismatched hashes	.log, .json
Determinism Logs	Records of RNG states, seeds, and hash checks	.json
Summary Reports	Aggregated pass/fail and coverage	.md, .json
Audit Logs	Digitally signed releases of log bundles	.zip, .sig
IV. Deterministic Logging Policy
Parameter	Rule
Timestamps	UTC-only, ISO 8601 (2025-11-01T17:03:00Z)
Float Precision	Fixed to 1e‚Åª‚Å∂
Ordering	Lexicographic (by test name)
RNG State	Serialized to file before and after test
Seed Capture	Must record all RNGs (Python, NumPy, Torch)
Environment Variables	Logged as hash digest (privacy-safe)
Machine ID	Abstracted; only architecture & OS logged
Reproducibility	Must be re-runnable from determinism/ trace
V. File Naming Convention

Format:

<YYYYMMDD>__<TESTSUITE>__<CATEGORY>.log


Examples:

20251101__unit_tensor_ops__run.log

20251101__integration_bridge__timing.json

20251101__regression_dream_pool__determinism.json

20251101__performance_fullsuite__summary.md

VI. Log Record Schema

Each test execution log contains the following structure:

{
  "test_name": "test_tensor_normalization",
  "timestamp_start": "2025-11-01T17:00:05Z",
  "timestamp_end": "2025-11-01T17:00:05Z",
  "duration_ms": 2.32,
  "status": "PASS",
  "seed": 42,
  "rng_state": {
    "python": "0x3fe102...",
    "numpy": "MTIzNDU2...",
    "torch": "ab98cd..."
  },
  "inputs": {
    "fixture": "chromatic/mock_tensor_001.npy",
    "hash": "8b4f41d6e..."
  },
  "outputs": {
    "result_hash": "cc923eb92a...",
    "loss": 0.003021,
    "coherence": 0.9123
  },
  "determinism_check": "verified",
  "environment": {
    "os": "Windows 10",
    "arch": "x86_64",
    "python_version": "3.11.6"
  },
  "signature": "SHA256:af124cb3c6..."
}

VII. Deterministic Replay Workflow
Phase	Script	Purpose
1. Log Export	export_last_run_logs.py	Collects all .log and .json files from /runs
2. Replay Initialization	replay_from_log.py	Loads seeds and fixtures from the determinism log
3. Test Replay	pytest --replay	Runs tests using captured RNG states
4. Comparison	compare_replay_hashes.py	Verifies output hashes and metadata equality
5. Report	generate_replay_report.py	Summarizes pass/fail, timing drift, and precision Œî

Successful replay requires bit-identical output; any deviation above 1e‚Åª‚Å∏ triggers an audit alert.

VIII. Timing Logs

Timing precision is enforced with monotonic nanosecond counters (Python‚Äôs time.perf_counter_ns()).

Output format (.csv):

test_name	start_ns	end_ns	duration_ns	duration_ms	memory_mb	cpu_util
test_dream_pool_retrieval	1002823	1005567	2744	2.74	52	12.3

Averages and variances are aggregated into timing_summary.json.

IX. Error Logs

Error logs contain full tracebacks, fixture hashes, and reproduction commands:

Example:

[2025-11-01T17:02:14Z] ERROR: AssertionError
  Test: test_bridge_roundtrip
  Fixture: spectral/mock_spectrum_01.npy
  Expected Œî < 1e-6, got 2.1e-5
  Command: pytest tests/integration/test_bridge_roundtrip.py -k "roundtrip"


Errors are auto-triaged by severity:

‚ö†Ô∏è Minor (numerical drift)

‚ùó Moderate (hash mismatch)

üö´ Critical (determinism failure or seed corruption)

X. Log Signing and Archival

At the end of each CI run:

All .log, .json, .csv, .md under /logs are bundled.

A digest manifest is generated:

sha256sum * > manifest.sha256


The bundle is compressed:

zip -r logs_audit_2025_11_01.zip ./runs ./timing ./determinism ./summaries


It is signed using project keys:

gpg --sign logs_audit_2025_11_01.zip


The signed archive is moved to /audit/ and referenced by the chronicle.

XI. Integration With Core Meta Chronicle

Every test batch execution registers a new Chronicle record:

{
  "event": "TEST_SUITE_EXECUTED",
  "timestamp": "2025-11-01T17:05:00Z",
  "artifact": "logs_audit_2025_11_01.zip",
  "signature": "gpg:valid",
  "hash": "d302fa09...",
  "verdict": "PASS"
}


This guarantees end-to-end traceability from experiment ‚Üí test ‚Üí release artifact.

XII. Compliance Rules
Rule	Constraint
Encoding	UTF-8
Hash Algorithm	SHA-256
Timezone	UTC
Float Precision	1e‚Åª‚Å∂
Log Rotation	30 days
Signed Archives	Required for releases
Replay Verification	Œî ‚â§ 1e‚Åª‚Å∏
Determinism	Mandatory for all test categories
File Naming	<date>__<suite>__<category>.log
XIII. Compliance Summary
Field	Specification
Spec Version	1.0
Determinism Level	Bit-Exact
Hash Drift Tolerance	‚â§ 1e‚Åª‚Å∏
Replay Mode	Fully Reproducible
Audit Authority	Codex Validation Agent
Retention Period	90 Days
Status	‚úÖ Verified Deterministic Log System